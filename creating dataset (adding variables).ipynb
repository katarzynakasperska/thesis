{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1XSPJEvRe9vDmLX5V4-lTmGiZ1XNvpD6T","timestamp":1669293246493}],"authorship_tag":"ABX9TyOOAP0XL7PRaTyf39x1zuBv"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"K6Iinf6Ig2nf"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["!pip install pronouncing"],"metadata":{"id":"EnFA1s6ThR0s"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas\n","import seaborn as sns\n","import pronouncing \n","from google.colab import files"],"metadata":{"id":"8iFBTslehO03"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#loading data with the last words of the songs\n","out = pandas.read_excel('/content/drive/MyDrive/thesis/output.xlsx')\n","out = out.values.tolist()\n","for i in range (0, len(out)):\n","    out[i] = [x for x in out[i] if str(x) != 'nan']\n","\n","print(\"Done\")"],"metadata":{"id":"7klIqVJJheL9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#indices of songs for which the lyrics hasn't been found\n","no_lyrics = pandas.read_excel('/content/drive/MyDrive/thesis/indices_no_lyrics.xlsx')\n","no_lyrics = no_lyrics[0].tolist()\n","\n","print(len(no_lyrics))"],"metadata":{"id":"VcAWeC1XhraI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#check the length of each song - useful for normalization of the rhyme score\n","length = []\n","for i in range (0, len(out)):\n","    length.append(len(out[i]))\n","\n","print(\"Done\")"],"metadata":{"id":"vMmyAmBuh3kR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#see distribution of lengths of the songs, sometimes the program might have captured non-lyrics but treated them as lyrics\n","#it can be seen that above 100 are probably outliers, but just to be safe I'll put the threshold for non-lyrics to 150\n","sns.boxplot(x=length)"],"metadata":{"id":"TNOMdL3viARS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#indices of the songs that probably don't have actual lyrics\n","#will delete those later\n","\n","too_long = []\n","for i in range (0, len(length)):\n","    if length[i] > 150:\n","        too_long.append(i)\n","        \n","print(len(too_long))"],"metadata":{"id":"b_LfuTKpiDnH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#score based on rhymes\n","#coupled rhymes\n","\n","count_rhymes_coupled = []\n","\n","for i in range (0, len(out)):\n","    j = 0\n","    count = 0\n","    while j+1 < len(out[i]):\n","        if out[i][j] in pronouncing.rhymes(out[i][j+1]):\n","            count += 1\n","        j += 2\n","    count_rhymes_coupled.append(int(count))\n","\n","print(\"Done\")"],"metadata":{"id":"wE846xz4iGhq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#score based on rhymes\n","#alternating rhymes\n","\n","count_rhymes_alternating = []\n","\n","for i in range (0, len(out)):\n","    j = 0\n","    count = 0\n","    while j+2 < len(out[i]):\n","        if out[i][j] in pronouncing.rhymes(out[i][j+2]):\n","            count += 1\n","        j += 1\n","    count_rhymes_alternating.append(int(count))\n","\n","print(\"Done\")"],"metadata":{"id":"65MbOZgXiLwB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#score based on rhymes\n","#same words\n","\n","count_rhymes_same = []\n","\n","for i in range (0, len(out)):\n","    j = 0\n","    count = 0\n","    while j+1 < len(out[i]):\n","        if out[i][j] == out[i][j+1]:\n","            count += 1\n","        j += 2\n","    count_rhymes_same.append(int(count))\n","\n","print(\"Done\")"],"metadata":{"id":"hGR_pnj2iOft"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#sum of all values of rhymes\n","sum_rhymes = [count_rhymes_coupled[i]+count_rhymes_alternating[i]+count_rhymes_same[i] for i in range(len(count_rhymes_coupled))]\n","print(\"Done\")"],"metadata":{"id":"gcu_nGXuiShe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sns.boxplot(x=sum_rhymes)"],"metadata":{"id":"wZPfIiXhiUMS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#normalization of the rhyme values\n","normalization_rhymes = [round(sum_rhymes[i]/length[i], 2) for i in range(len(sum_rhymes))]\n","norm_coupled = [round(count_rhymes_coupled[i]/length[i], 2) for i in range(len(count_rhymes_coupled))]\n","norm_alternating = [round(count_rhymes_alternating[i]/length[i], 2) for i in range(len(count_rhymes_alternating))]\n","norm_same = [round(count_rhymes_same[i]/length[i], 2) for i in range(len(count_rhymes_same))]\n","\n","print(\"Done\")"],"metadata":{"id":"28nHex31iclO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#loading data with all the songs and information about their peak rank\n","data = pandas.read_excel('/content/drive/MyDrive/thesis/dataset.xlsx')\n","peak_rank = data['peak.rank'].tolist()\n","print(\"Done\")"],"metadata":{"id":"jhVCsq91iiXN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#which 10th of the chart it is\n","rank_10 = []\n","for i in range (0, len(peak_rank)):\n","    if 10 >= peak_rank[i] > 0:\n","        rank_10.append(1)\n","    elif 20 >= peak_rank[i] >= 11:\n","        rank_10.append(2)\n","    elif 30 >= peak_rank[i] >= 21:\n","        rank_10.append(3)\n","    elif 40 >= peak_rank[i] >= 31:\n","        rank_10.append(4)\n","    elif 50 >= peak_rank[i] >= 41:\n","        rank_10.append(5)\n","    elif 60 >= peak_rank[i] >= 51:\n","        rank_10.append(6)\n","    elif 70 >= peak_rank[i] >= 61:\n","        rank_10.append(7)\n","    elif 80 >= peak_rank[i] >= 71:\n","        rank_10.append(8)\n","    elif 90 >= peak_rank[i] >= 81:\n","        rank_10.append(9)\n","    else:\n","        rank_10.append(10)\n","        \n","print(\"Done\")"],"metadata":{"id":"qIFnWjwfi996"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#adding new columns to the dataset \n","data['ranks_10'] = rank_10\n","data['rhyme_score'] = normalization_rhymes\n","data['coupled'] = norm_coupled\n","data['alternating'] = norm_alternating\n","data['same'] = norm_same\n","data['length'] = length\n","\n","print(data)"],"metadata":{"id":"akLQ4xV0jIqi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#deleting rows which don't have lyrics\n","no_lyrics_total = no_lyrics + too_long\n","end_data = data.drop(no_lyrics_total)\n","print(end_data)"],"metadata":{"id":"qJVzFK2ujhdq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#loading data with the number of second-person pronouns per song\n","data_you = pandas.read_excel('/content/drive/MyDrive/thesis/you_all.xlsx')\n","number_you = data_you[0].tolist()\n","print(\"Done\")"],"metadata":{"id":"iThrHX9t2XCy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#normalization of the number of second-person pronouns\n","updated_length = list(end_data['length'])\n","norm_you = [round(number_you[i]/updated_length[i], 2) for i in range(len(number_you))]\n","print(\"Done\")"],"metadata":{"id":"MQyHyRsN27E4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["end_data['number_you'] = number_you\n","end_data['norm_you'] = norm_you\n","print(\"Done\")"],"metadata":{"id":"LOAuFY0e2jKg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["writer = pandas.ExcelWriter('end_data.xlsx', engine='xlsxwriter')\n","end_data.to_excel(writer, index=False)\n","writer.save()\n","print(\"Done\")"],"metadata":{"id":"2eP7HzhQkW9M"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["files.download('end_data.xlsx') "],"metadata":{"id":"u7NyLkPFkdgA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#subset that is going to be used for the models\n","subset = end_data[end_data[\"ranks_10\"].isin([1, 10])]\n","\n","ranks_10 = subset['ranks_10'].tolist()\n","\n","hit = []\n","for i in range (0, len(ranks_10)):\n","    if ranks_10[i] == 1:\n","        hit.append(1)\n","    else:\n","        hit.append(0)\n","       \n","subset['hit'] = hit\n","\n","subset"],"metadata":{"id":"WjOOTinlphel"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["end_subset = subset[subset[\"length\"]>15]"],"metadata":{"id":"_OlhdeS8L0aB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["writer = pandas.ExcelWriter('subset.xlsx', engine='xlsxwriter')\n","end_subset.to_excel(writer, index=False)\n","writer.save()\n","print(\"Done\")"],"metadata":{"id":"4cEM4pVipv1n"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["files.download('subset.xlsx') "],"metadata":{"id":"HXcpnFYlqFAK"},"execution_count":null,"outputs":[]}]}